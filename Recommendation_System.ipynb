{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
        "from sklearn.metrics import mean_squared_error, r2_score, accuracy_score, classification_report\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "import shap\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load dataset\n",
        "df = pd.read_csv(\"anime.csv\")  # Replace with actual dataset path\n",
        "\n",
        "# Handling missing values\n",
        "for column in df.select_dtypes(include=np.number).columns:\n",
        "    df[column].fillna(df[column].median(), inplace=True)\n",
        "\n",
        "# Feature Engineering: Adding interaction terms, user-item interactions\n",
        "# Converting 'name' and 'anime_id' to numerical type before multiplication\n",
        "df['name'] = pd.factorize(df['name'])[0]  # Convert 'name' to numerical representation\n",
        "df['anime_id'] = pd.factorize(df['anime_id'])[0]  # Convert 'anime_id' to numerical representation\n",
        "df['User_Item_Interaction'] = df['name'] * df['anime_id']  # Example feature\n",
        "\n",
        "# Encoding categorical variables\n",
        "df = pd.get_dummies(df, columns=['genre', 'type'], drop_first=True)\n",
        "\n",
        "# Splitting dataset into features and target\n",
        "X = df.drop(columns=['rating'])  # Replace 'Recommendation' with actual target column\n",
        "y = df['rating']\n",
        "\n",
        "# Ensure y is of numeric type and handle potential errors\n",
        "y = pd.to_numeric(y, errors='coerce')  # Convert to numeric, replace invalid with NaN\n",
        "y.fillna(y.median(), inplace=True)  # Fill NaN with median if any\n",
        "\n",
        "# ---Changes start here---\n",
        "# Identify and convert or drop columns with 'Unknown'\n",
        "for col in X.select_dtypes(include=['object']).columns:\n",
        "    if X[col].str.contains('Unknown').any():\n",
        "        # Option 1: Convert 'Unknown' to a numerical value (e.g., -1)\n",
        "        # X[col] = X[col].replace('Unknown', -1)\n",
        "        # Option 2: Drop the column\n",
        "        X = X.drop(columns=[col])\n",
        "\n",
        "# Feature Scaling after handling 'Unknown' values\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "# Train-test split\n",
        "# Assuming y_resampled should be y, as y_resampled is not defined in the original code\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Model Training with Hyperparameter Tuning\n",
        "param_grid = {\n",
        "    'n_estimators': [100, 200],\n",
        "    'max_depth': [10, 20, None],\n",
        "    'min_samples_split': [2, 5],\n",
        "    'min_samples_leaf': [1, 2]\n",
        "}\n",
        "\n",
        "# Choose appropriate model based on the nature of your target variable 'rating'\n",
        "# If 'rating' is continuous, use RandomForestRegressor\n",
        "# If 'rating' is categorical, use RandomForestClassifier\n",
        "# Here, assuming 'rating' is continuous, but change to Classifier if needed\n",
        "model = RandomForestRegressor(random_state=42)\n",
        "# model = RandomForestClassifier(random_state=42) # Uncomment if 'rating' is categorical\n",
        "\n",
        "grid_search = GridSearchCV(model, param_grid, cv=5, n_jobs=-1)\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Best Model\n",
        "best_model = grid_search.best_estimator_\n",
        "y_pred = best_model.predict(X_test)\n",
        "\n",
        "# Choose appropriate evaluation metrics based on the model type (Regressor or Classifier)\n",
        "if isinstance(best_model, RandomForestRegressor):\n",
        "    print(\"Mean Squared Error:\", mean_squared_error(y_test, y_pred))\n",
        "    print(\"R-squared:\", r2_score(y_test, y_pred))\n",
        "elif isinstance(best_model, RandomForestClassifier):\n",
        "    print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "    print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
        "\n",
        "# Feature Importance Analysis\n",
        "explainer = shap.TreeExplainer(best_model)\n",
        "shap_values = explainer.shap_values(X_test)\n",
        "shap.summary_plot(shap_values, X_test, feature_names=X.columns)\n",
        "\n",
        "# Visualization\n",
        "feature_importances = pd.Series(best_model.feature_importances_, index=X.columns)\n",
        "feature_importances.nlargest(10).plot(kind='barh')\n",
        "plt.title(\"Top 10 Important Features\")\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FSUI6QCS4a7j",
        "outputId": "0079ea4b-adb7-443f-c481-4e1b0bd79cf0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-1-f855b643b14a>:16: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df[column].fillna(df[column].median(), inplace=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(df.columns)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "maxnFh5L0yBp",
        "outputId": "a533b5cf-45cb-4501-9ed5-e73b1c548675"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['anime_id', 'name', 'genre', 'type', 'episodes', 'rating', 'members'], dtype='object')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Interview questions\n",
        "\n",
        "1.Difference Between User-Based and Item-Based Collaborative Filtering\n",
        "Collaborative filtering is a technique used in recommendation systems that suggests items based on user behavior and preferences. It comes in two main types:\n",
        "\n",
        "Feature\tUser-Based Collaborative Filtering\tItem-Based Collaborative Filtering\n",
        "Definition\tFinds users similar to the target user and recommends items liked by those similar users.\tFinds items similar to the ones the user has interacted with and recommends those similar items.\n",
        "Similarity Calculation\tCompares users based on their past interactions with items.\tCompares items based on how users have interacted with them.\n",
        "Example\tIf User A and User B have similar tastes, and User B liked a movie, then User A is likely to enjoy it too.\tIf two movies are frequently watched by the same users, then a user who watches one may be recommended the other.\n",
        "Scalability\tLess scalable due to the high number of users and dynamic nature of user preferences.\tMore scalable because item relationships remain relatively stable over time.\n",
        "Common Algorithms\tPearson Correlation, Cosine Similarity on user-item matrix.\tCosine Similarity, Jaccard Similarity on item-user matrix.\n",
        "\n",
        "2.What is Collaborative Filtering, and How Does It Work?\n",
        "Collaborative filtering is a recommendation technique that suggests items based on the preferences and behaviors of users. It works on the assumption that if two users agree on one item, they are likely to agree on other items as well.\n",
        "\n",
        "How It Works:\n",
        "Collect Data – User interactions (e.g., ratings, purchases, clicks) are collected.\n",
        "Create a Matrix – A user-item interaction matrix is created where rows represent users, and columns represent items.\n",
        "Compute Similarity – Based on past interactions, user similarity (user-based CF) or item similarity (item-based CF) is calculated.\n",
        "Generate Recommendations – Using the similarity scores, predictions are made for items that a user may like.\n",
        "Rank & Present – The system ranks the recommendations and presents the most relevant ones.\n",
        "Types of Collaborative Filtering:\n",
        "Memory-Based – Directly uses similarity measures (e.g., Pearson correlation, cosine similarity).\n",
        "Model-Based – Uses machine learning techniques (e.g., matrix factorization, deep learning) to learn latent patterns and make recommendations."
      ],
      "metadata": {
        "id": "BPvBZCoZ9qrN"
      }
    }
  ]
}